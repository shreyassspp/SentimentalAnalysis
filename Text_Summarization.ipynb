{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Text Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkVAXuUXizyU"
      },
      "source": [
        "**Importing libraries and getting links for articles**\n",
        "\n"
      ],
      "id": "RkVAXuUXizyU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bp_v0u5VpLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa288ed1-9f63-4b05-d9ff-87c69f9966a7"
      },
      "source": [
        "!pip install newsapi-python\n",
        "from newsapi import NewsApiClient\n",
        "# Init\n",
        "newsapi = NewsApiClient(api_key='806638da1edd45aab2f9ad3bad488802')\n",
        "query=input(\"Enter the search query: \")\n",
        "start=input(\"Enter the start date in YYYY-MM-DD Format: \")\n",
        "ending=input(\"Enter the ending date in YYYY-MM-DD Format: \")\n",
        "\n",
        "# /v2/everything\n",
        "all_articles = newsapi.get_everything(q=query,\n",
        "                                      sources='bbc-news,the-verge',\n",
        "                                      domains='bbc.co.uk,techcrunch.com',\n",
        "                                      from_param=start,\n",
        "                                      to=ending,\n",
        "                                      language='en',\n",
        "                                      sort_by='relevancy',\n",
        "                                      page=2)\n",
        "\n",
        "links=[]\n",
        "for i in all_articles['articles']:\n",
        "  links.append(i['url'])\n",
        "\n"
      ],
      "id": "0bp_v0u5VpLA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: newsapi-python in /usr/local/lib/python3.7/dist-packages (0.2.6)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.7/dist-packages (from newsapi-python) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->newsapi-python) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->newsapi-python) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->newsapi-python) (1.24.3)\n",
            "Enter the search query: coronavirus\n",
            "Enter the start date in YYYY-MM-DD Format: 2021-05-01\n",
            "Enter the ending date in YYYY-MM-DD Format: 2021-05-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmgdFYbDvECA"
      },
      "source": [
        "Scrapping Data from Net"
      ],
      "id": "bmgdFYbDvECA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SfRESDcizc6"
      },
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "article_text = \"\"\n",
        "for i in links:\n",
        "  scraped_data = urllib.request.urlopen(i)\n",
        "  article = scraped_data.read()\n",
        "  parsed_article = bs.BeautifulSoup(article,'lxml')\n",
        "  paragraphs = parsed_article.find_all('p')\n",
        "  for p in paragraphs:\n",
        "    article_text += p.text\n",
        "\n",
        "print(article_text)"
      ],
      "id": "_SfRESDcizc6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "descending-spiritual"
      },
      "source": [
        "# **Fetching Articles from NewsAPI**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "id": "descending-spiritual"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "filled-layout"
      },
      "source": [
        "# **Preprocessing**"
      ],
      "id": "filled-layout"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "featured-movie"
      },
      "source": [
        "# Removing Square Brackets and Extra Spaces\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)"
      ],
      "id": "featured-movie",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "completed-pollution"
      },
      "source": [
        "# Removing special characters and digits\n",
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)"
      ],
      "id": "completed-pollution",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urban-syracuse"
      },
      "source": [
        "# **Converting Text To Sentences**"
      ],
      "id": "urban-syracuse"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "angry-fields",
        "outputId": "fd2fa656-7d2c-48f8-899d-a794f48fa34c"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "sentence_list = nltk.sent_tokenize(article_text)"
      ],
      "id": "angry-fields",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "particular-sperm"
      },
      "source": [
        "# **Find Weighted Frequency of Occurrence**"
      ],
      "id": "particular-sperm"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acoustic-occasions"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "id": "acoustic-occasions",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "composed-fault"
      },
      "source": [
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "id": "composed-fault",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "western-young"
      },
      "source": [
        "# **Calculating Sentence Scores**"
      ],
      "id": "western-young"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "continued-competition"
      },
      "source": [
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "id": "continued-competition",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "developed-choir"
      },
      "source": [
        "# **Getting the Summary**"
      ],
      "id": "developed-choir"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "differential-breach",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "896d1e1e-a3a1-4091-9f05-f4cc835204e4"
      },
      "source": [
        "import heapq\n",
        "summary_sentences = heapq.nlargest(10, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)"
      ],
      "id": "differential-breach",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BBC is not responsible for the content of external sites. It caused outrage among Colombians already battered by the pandemic and the protests were joined by many middle-class people who feared the changes could see them slip into poverty. It would also have eliminated many of the current exemptions enjoyed by individuals, as well as increasing taxes imposed on businesses. The government says cases are \"slowing down\" - but testing numbers have also dipped, meaning the true number of cases could be far higher than official figures suggest. At least 800 people were injured as the police clashed with demonstrators in major cities.Human rights groups and protesters have accused riot police squads of using unnecessary force. \"We had requested a testing facility but the government said they could not give the permission,\" said Dr Kharel. \"Thanks to this programme, close to a million people here have already received their first vaccine dose, helping society to emerge carefully from lockdown. This is where basically most of our life happens.“Because people don’t eat ice-cream the whole day and people don’t eat kale the whole day. The UN said it was particularly shocked by events in Cali on Monday, where it said police had fired on protesters. \"We did have patients come to us from the Everest region who tested positive at our hospital a couple of weeks back,\" said staff member Astha Pant.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}